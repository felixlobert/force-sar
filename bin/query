#!/usr/bin/python3

from src import utils
import geopandas as gpd
import pandas as pd
from multiprocessing.pool import ThreadPool as Pool
import click

@click.command()
@click.argument('prm_file', type=click.Path(exists=True))
@click.argument('out_path', type=click.Path(exists=True))

def query(prm_file, out_path):
    """Query satellite data matching given criteria in PRM_FILE and writing the results to a geojson file stored in OUT_PATH"""
    
    prm = utils.read_prm(prm_file)

    # find common tiles from defined range and oprional tile file
    x_range = [int(i) for i in prm['X_TILE_RANGE'].split(' ')]
    x_range = list(range(x_range[0], x_range[1] + 1))
    x_range = [str(i).zfill(4) for i in x_range]

    y_range = [int(i) for i in prm['Y_TILE_RANGE'].split(' ')]
    y_range = list(range(y_range[0], y_range[1] + 1))
    y_range = [str(i).zfill(4) for i in y_range]

    tiles = ['X' + x_tile + '_Y' + y_tile for x_tile in x_range for y_tile in y_range]

    if prm['FILE_TILE'] != 'NULL':
        tiles_file = utils.read_til(prm['FILE_TILE'])
        tiles = set(tiles).intersection(tiles_file)


    # read and filter force grid for tile list
    force_grid = gpd.read_file(prm['FORCE_GRID'])
    force_grid = force_grid[force_grid['Tile_ID'].isin(tiles)]


    # if asf api is chosen
    if prm['DATA_SOURCE'] == 'ASF':

        # start parallel search for each orbit if orbit(s) set in prm file
        if prm['ORBITS'] != 'NULL':

            orbits = prm['ORBITS'].split(' ')
                
            def get_scenes_per_orbit(orbit):

                scenes = utils.get_scenes_asf(
                aoi = force_grid,
                start_date = prm['DATE_RANGE'].split(' ')[0],
                end_date = prm['DATE_RANGE'].split(' ')[1],
                relative_orbit = orbit)

                return scenes

            # create the process pool and search for scenes in parallel
            with Pool(int(prm['NTHREAD'])) as pool:
                scenes = pd.concat(pool.map(get_scenes_per_orbit, orbits))

        else:

            # query available scenes from api and filter for orbits from prm file
            scenes = utils.get_scenes_asf(
                aoi = force_grid,
                start_date = prm['DATE_RANGE'].split(' ')[0],
                end_date = prm['DATE_RANGE'].split(' ')[1])
            
    else:        
        # start parallel search for each orbit if orbit(s) set in prm file
        if prm['ORBITS'] != 'NULL':

            orbits = prm['ORBITS'].split(' ')
                
            def get_scenes_per_orbit(orbit):

                scenes = utils.get_scenes_creodias(
                aoi = force_grid,
                satellite = 'Sentinel1',
                start_date = prm['DATE_RANGE'].split(' ')[0],
                end_date = prm['DATE_RANGE'].split(' ')[1],
                product_type = 'GRD', 
                relative_orbit = orbit,
                sensor_mode = 'IW',
                repo = prm['DATA_SOURCE'])

                return scenes

            # create the process pool and search for scenes in parallel
            with Pool(int(prm['NTHREAD'])) as pool:
                scenes = pd.concat(pool.map(get_scenes_per_orbit, orbits))

        else:

            # query available scenes from api and filter for orbits from prm file
            scenes = utils.get_scenes_creodias(
                aoi = force_grid,
                satellite = 'Sentinel1',
                start_date = prm['DATE_RANGE'].split(' ')[0],
                end_date = prm['DATE_RANGE'].split(' ')[1],
                product_type = 'GRD',
                sensor_mode = 'IW',
                repo = prm['DATA_SOURCE'])


    scenes.to_file(out_path + 'scenes.geojson', driver='GeoJSON')


if __name__ == '__main__':
    query()